{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28cd50e",
   "metadata": {},
   "source": [
    "## Commit\n",
    "\n",
    "Running the cell below copies any local source code modifications into the FlashAttention install directory on the FlashAttention docker image, and then commits the Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "59630d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "Creating flash-attention_flashattention_run ... \n",
      "\u001b[1Bting flash-attention_flashattention_run ... \u001b[32mdone\u001b[0m\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "WARNING: CUDA Minor Version Compatibility mode ENABLED.\n",
      "  Using driver version 515.86.01 which has support for CUDA 11.7.  This container\n",
      "  was built with CUDA 11.8 and will be run in Minor Version Compatibility mode.\n",
      "  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use\n",
      "  with this container but was unavailable:\n",
      "  [[]]\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "\n",
      "\n",
      "torch.__version__  = 1.14.0a0+410ce96\n",
      "\n",
      "\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing flash_attn.egg-info/PKG-INFO\n",
      "writing dependency_links to flash_attn.egg-info/dependency_links.txt\n",
      "writing requirements to flash_attn.egg-info/requires.txt\n",
      "writing top-level names to flash_attn.egg-info/top_level.txt\n",
      "reading manifest file 'flash_attn.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "warning: no files found matching '*.cu' under directory 'flash_attn'\n",
      "warning: no files found matching '*.h' under directory 'flash_attn'\n",
      "warning: no files found matching '*.cuh' under directory 'flash_attn'\n",
      "warning: no files found matching '*.cpp' under directory 'flash_attn'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'AUTHORS'\n",
      "writing manifest file 'flash_attn.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "running build_ext\n",
      "building 'flash_attn_cuda' extension\n",
      "Emitting ninja build file /home/workspace/build/temp.linux-x86_64-3.8/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/1] c++ -MMD -MF /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/fmha_api.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/workspace/csrc/flash_attn -I/home/workspace/csrc/flash_attn/src -I/home/workspace/csrc/flash_attn/cutlass/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/workspace/csrc/flash_attn/fmha_api.cpp -o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/fmha_api.o -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=flash_attn_cuda -D_GLIBCXX_USE_CXX11_ABI=1\n",
      "In file included from /home/workspace/csrc/flash_attn/src/fmha.h:42,\n",
      "                 from /home/workspace/csrc/flash_attn/fmha_api.cpp:33:\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h: In function ‘void set_alpha(uint32_t&, float, Data_type)’:\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h:63:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "   63 |         alpha = reinterpret_cast<const uint32_t &>( h2 );\n",
      "      |                                                     ^~\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h:68:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "   68 |         alpha = reinterpret_cast<const uint32_t &>( h2 );\n",
      "      |                                                     ^~\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h:70:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "   70 |         alpha = reinterpret_cast<const uint32_t &>( norm );\n",
      "      |                                                     ^~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp: In function ‘void set_params_fprop(FMHA_fprop_params&, size_t, size_t, size_t, size_t, size_t, at::Tensor, at::Tensor, at::Tensor, at::Tensor, void*, void*, void*, void*, void*, float, float, bool, int)’:\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:64:38: warning: ‘void* memset(void*, int, size_t)’ clearing an object of non-trivial type ‘struct FMHA_fprop_params’; use assignment or value-initialization instead [-Wclass-memaccess]\n",
      "   64 |     memset(&params, 0, sizeof(params));\n",
      "      |                                      ^\n",
      "In file included from /home/workspace/csrc/flash_attn/fmha_api.cpp:33:\n",
      "/home/workspace/csrc/flash_attn/src/fmha.h:75:8: note: ‘struct FMHA_fprop_params’ declared here\n",
      "   75 | struct FMHA_fprop_params : public Qkv_params {\n",
      "      |        ^~~~~~~~~~~~~~~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:60:15: warning: unused variable ‘acc_type’ [-Wunused-variable]\n",
      "   60 |     Data_type acc_type = DATA_TYPE_FP32;\n",
      "      |               ^~~~~~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp: In function ‘std::vector<at::Tensor> mha_fwd(const at::Tensor&, const at::Tensor&, const at::Tensor&, at::Tensor&, const at::Tensor&, const at::Tensor&, int, int, float, float, bool, bool, bool, int, c10::optional<at::Generator>)’:\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:265:10: warning: unused variable ‘is_sm80’ [-Wunused-variable]\n",
      "  265 |     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;\n",
      "      |          ^~~~~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp: In function ‘std::vector<at::Tensor> mha_fwd_block(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int, int, float, float, bool, bool, c10::optional<at::Generator>)’:\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:604:10: warning: unused variable ‘is_sm80’ [-Wunused-variable]\n",
      "  604 |     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;\n",
      "      |          ^~~~~~~\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/fmha_api.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_fwd_hdim32.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_fwd_hdim64.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_fwd_hdim128.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_bwd_hdim32.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_bwd_hdim64.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_bwd_hdim128.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.8/flash_attn_cuda.cpython-38-x86_64-linux-gnu.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn_cuda.cpython-38-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/losses\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/losses/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/losses\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/losses/cross_entropy.py -> build/bdist.linux-x86_64/egg/flash_attn/losses\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_triton_onewritehead.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_triton_og.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_interface.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/layers/patch_embed.py -> build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/layers/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/layers/rotary.py -> build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_blocksparse_attn_interface.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/fused_softmax.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_triton.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/bert_padding.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_blocksparse_attention.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/activations.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/rms_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/layer_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/fused_dense.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/pretrained.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/generation.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/benchmark.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/distributed.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/embedding.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/block.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/mlp.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/mha.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attention.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/gpt.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/llama.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/gptj.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/bert.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/vit.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/opt.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/losses/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/losses/cross_entropy.py to cross_entropy.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_onewritehead.py to flash_attn_triton_onewritehead.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_og.py to flash_attn_triton_og.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_interface.py to flash_attn_interface.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/patch_embed.py to patch_embed.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/rotary.py to rotary.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_blocksparse_attn_interface.py to flash_blocksparse_attn_interface.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/fused_softmax.py to fused_softmax.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton.py to flash_attn_triton.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/bert_padding.py to bert_padding.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_blocksparse_attention.py to flash_blocksparse_attention.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/activations.py to activations.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/rms_norm.py to rms_norm.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/layer_norm.py to layer_norm.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/fused_dense.py to fused_dense.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/pretrained.py to pretrained.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/generation.py to generation.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/benchmark.py to benchmark.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/distributed.py to distributed.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/embedding.py to embedding.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/block.py to block.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/mlp.py to mlp.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/mha.py to mha.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attention.py to flash_attention.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gpt.py to gpt.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/llama.py to llama.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gpt_neox.py to gpt_neox.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gptj.py to gptj.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/bert.py to bert.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/vit.py to vit.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/opt.py to opt.cpython-38.pyc\n",
      "creating stub loader for flash_attn_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn_cuda.py to flash_attn_cuda.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.flash_attn_cuda.cpython-38: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 'dist/flash_attn-1.0.4-py3.8-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing flash_attn-1.0.4-py3.8-linux-x86_64.egg\n",
      "removing '/usr/local/lib/python3.8/dist-packages/flash_attn-1.0.4-py3.8-linux-x86_64.egg' (and everything under it)\n",
      "creating /usr/local/lib/python3.8/dist-packages/flash_attn-1.0.4-py3.8-linux-x86_64.egg\n",
      "Extracting flash_attn-1.0.4-py3.8-linux-x86_64.egg to /usr/local/lib/python3.8/dist-packages\n",
      "flash-attn 1.0.4 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /usr/local/lib/python3.8/dist-packages/flash_attn-1.0.4-py3.8-linux-x86_64.egg\n",
      "Processing dependencies for flash-attn==1.0.4\n",
      "Searching for packaging==22.0\n",
      "Best match: packaging 22.0\n",
      "Adding packaging 22.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for einops==0.6.1\n",
      "Best match: einops 0.6.1\n",
      "Adding einops 0.6.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for torch==1.14.0a0+410ce96\n",
      "Best match: torch 1.14.0a0+410ce96\n",
      "Adding torch 1.14.0a0+410ce96 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
      "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
      "Installing torchrun script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for networkx==2.6.3\n",
      "Best match: networkx 2.6.3\n",
      "Adding networkx 2.6.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for sympy==1.11.1\n",
      "Best match: sympy 1.11.1\n",
      "Adding sympy 1.11.1 to easy-install.pth file\n",
      "Installing isympy script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for typing-extensions==4.4.0\n",
      "Best match: typing-extensions 4.4.0\n",
      "Adding typing-extensions 4.4.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for mpmath==1.2.1\n",
      "Best match: mpmath 1.2.1\n",
      "Adding mpmath 1.2.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Finished processing dependencies for flash-attn==1.0.4\n",
      "done\n",
      "commiting container\n",
      "sha256:880cf946d691b35ac08f4ab88f9d57fa34a98cc2b95490ed2c653158f6b87011\n",
      "force-quitting docker\n",
      "CONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS                NAMES\n",
      "3ae15de25859   1b06ac1005a9   \"/opt/nvidia/nvidia_…\"   40 seconds ago   Up 38 seconds   6006/tcp, 8888/tcp   flash-attention_flashattention_run_5dfe9e25780c\n",
      "3ae15de25859\n",
      "\u001b[31mERROR\u001b[0m: 137\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!./build_commit.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb5fea",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "7d543dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flash-attention_flashattention_run ... \n",
      "\u001b[1Bting flash-attention_flashattention_run ... \u001b[32mdone\u001b[0m\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "WARNING: CUDA Minor Version Compatibility mode ENABLED.\n",
      "  Using driver version 515.86.01 which has support for CUDA 11.7.  This container\n",
      "  was built with CUDA 11.8 and will be run in Minor Version Compatibility mode.\n",
      "  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use\n",
      "  with this container but was unavailable:\n",
      "  [[]]\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "usage: pytest [options] [file_or_dir] [file_or_dir] [...]\n",
      "\n",
      "positional arguments:\n",
      "  file_or_dir\n",
      "\n",
      "general:\n",
      "  -k EXPRESSION         Only run tests which match the given substring\n",
      "                        expression. An expression is a Python evaluatable\n",
      "                        expression where all names are substring-matched against\n",
      "                        test names and their parent classes. Example: -k\n",
      "                        'test_method or test_other' matches all test functions\n",
      "                        and classes whose name contains 'test_method' or\n",
      "                        'test_other', while -k 'not test_method' matches those\n",
      "                        that don't contain 'test_method' in their names. -k 'not\n",
      "                        test_method and not test_other' will eliminate the\n",
      "                        matches. Additionally keywords are matched to classes\n",
      "                        and functions containing extra names in their\n",
      "                        'extra_keyword_matches' set, as well as functions which\n",
      "                        have names assigned directly to them. The matching is\n",
      "                        case-insensitive.\n",
      "  -m MARKEXPR           Only run tests matching given mark expression. For\n",
      "                        example: -m 'mark1 and not mark2'.\n",
      "  --markers             show markers (builtin, plugin and per-project ones).\n",
      "  -x, --exitfirst       Exit instantly on first error or failed test\n",
      "  --fixtures, --funcargs\n",
      "                        Show available fixtures, sorted by plugin appearance\n",
      "                        (fixtures with leading '_' are only shown with '-v')\n",
      "  --fixtures-per-test   Show fixtures per test\n",
      "  --pdb                 Start the interactive Python debugger on errors or\n",
      "                        KeyboardInterrupt\n",
      "  --pdbcls=modulename:classname\n",
      "                        Specify a custom interactive Python debugger for use\n",
      "                        with --pdb.For example:\n",
      "                        --pdbcls=IPython.terminal.debugger:TerminalPdb\n",
      "  --trace               Immediately break when running each test\n",
      "  --capture=method      Per-test capturing method: one of fd|sys|no|tee-sys\n",
      "  -s                    Shortcut for --capture=no\n",
      "  --runxfail            Report the results of xfail tests as if they were not\n",
      "                        marked\n",
      "  --lf, --last-failed   Rerun only the tests that failed at the last run (or all\n",
      "                        if none failed)\n",
      "  --ff, --failed-first  Run all tests, but run the last failures first. This may\n",
      "                        re-order tests and thus lead to repeated fixture\n",
      "                        setup/teardown.\n",
      "  --nf, --new-first     Run tests from new files first, then the rest of the\n",
      "                        tests sorted by file mtime\n",
      "  --cache-show=[CACHESHOW]\n",
      "                        Show cache contents, don't perform collection or tests.\n",
      "                        Optional argument: glob (default: '*').\n",
      "  --cache-clear         Remove all cache contents at start of test run\n",
      "  --lfnf={all,none}, --last-failed-no-failures={all,none}\n",
      "                        Which tests to run with no previously (known) failures\n",
      "  --sw, --stepwise      Exit on test failure and continue from last failing test\n",
      "                        next time\n",
      "  --sw-skip, --stepwise-skip\n",
      "                        Ignore the first failing test but stop on the next\n",
      "                        failing test. Implicitly enables --stepwise.\n",
      "\n",
      "Reporting:\n",
      "  --durations=N         Show N slowest setup/test durations (N=0 for all)\n",
      "  --durations-min=N     Minimal duration in seconds for inclusion in slowest\n",
      "                        list. Default: 0.005.\n",
      "  -v, --verbose         Increase verbosity\n",
      "  --no-header           Disable header\n",
      "  --no-summary          Disable summary\n",
      "  -q, --quiet           Decrease verbosity\n",
      "  --verbosity=VERBOSE   Set verbosity. Default: 0.\n",
      "  -r chars              Show extra test summary info as specified by chars:\n",
      "                        (f)ailed, (E)rror, (s)kipped, (x)failed, (X)passed,\n",
      "                        (p)assed, (P)assed with output, (a)ll except passed\n",
      "                        (p/P), or (A)ll. (w)arnings are enabled by default (see\n",
      "                        --disable-warnings), 'N' can be used to reset the list.\n",
      "                        (default: 'fE').\n",
      "  --disable-warnings, --disable-pytest-warnings\n",
      "                        Disable warnings summary\n",
      "  -l, --showlocals      Show locals in tracebacks (disabled by default)\n",
      "  --no-showlocals       Hide locals in tracebacks (negate --showlocals passed\n",
      "                        through addopts)\n",
      "  --tb=style            Traceback print mode (auto/long/short/line/native/no)\n",
      "  --show-capture={no,stdout,stderr,log,all}\n",
      "                        Controls how captured stdout/stderr/log is shown on\n",
      "                        failed tests. Default: all.\n",
      "  --full-trace          Don't cut any tracebacks (default is to cut)\n",
      "  --color=color         Color terminal output (yes/no/auto)\n",
      "  --code-highlight={yes,no}\n",
      "                        Whether code should be highlighted (only if --color is\n",
      "                        also enabled). Default: yes.\n",
      "  --pastebin=mode       Send failed|all info to bpaste.net pastebin service\n",
      "  --junit-xml=path      Create junit-xml style report file at given path\n",
      "  --junit-prefix=str    Prepend prefix to classnames in junit-xml output\n",
      "\n",
      "pytest-warnings:\n",
      "  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS\n",
      "                        Set which warnings to report, see -W option of Python\n",
      "                        itself\n",
      "  --maxfail=num         Exit after first num failures or errors\n",
      "  --strict-config       Any warnings encountered while parsing the `pytest`\n",
      "                        section of the configuration file raise errors\n",
      "  --strict-markers      Markers not registered in the `markers` section of the\n",
      "                        configuration file raise errors\n",
      "  --strict              (Deprecated) alias to --strict-markers\n",
      "  -c file               Load configuration from `file` instead of trying to\n",
      "                        locate one of the implicit configuration files\n",
      "  --continue-on-collection-errors\n",
      "                        Force test execution even if collection errors occur\n",
      "  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path:\n",
      "                        'root_dir', './root_dir', 'root_dir/another_dir/';\n",
      "                        absolute path: '/home/user/root_dir'; path with\n",
      "                        variables: '$HOME/root_dir'.\n",
      "\n",
      "collection:\n",
      "  --collect-only, --co  Only collect tests, don't execute them\n",
      "  --pyargs              Try to interpret all arguments as Python packages\n",
      "  --ignore=path         Ignore path during collection (multi-allowed)\n",
      "  --ignore-glob=path    Ignore path pattern during collection (multi-allowed)\n",
      "  --deselect=nodeid_prefix\n",
      "                        Deselect item (via node id prefix) during collection\n",
      "                        (multi-allowed)\n",
      "  --confcutdir=dir      Only load conftest.py's relative to specified dir\n",
      "  --noconftest          Don't load any conftest.py files\n",
      "  --keep-duplicates     Keep duplicate tests\n",
      "  --collect-in-virtualenv\n",
      "                        Don't ignore tests in a local virtualenv directory\n",
      "  --import-mode={prepend,append,importlib}\n",
      "                        Prepend/append to sys.path when importing test modules\n",
      "                        and conftest files. Default: prepend.\n",
      "  --doctest-modules     Run doctests in all .py modules\n",
      "  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}\n",
      "                        Choose another output format for diffs on doctest\n",
      "                        failure\n",
      "  --doctest-glob=pat    Doctests file matching pattern, default: test*.txt\n",
      "  --doctest-ignore-import-errors\n",
      "                        Ignore doctest ImportErrors\n",
      "  --doctest-continue-on-failure\n",
      "                        For a given doctest, continue to run after the first\n",
      "                        failure\n",
      "  --xdoctest-modules, --xdoctest, --xdoc\n",
      "                        Run doctests in all .py modules using new style parsing\n",
      "  --xdoctest-glob=pat, --xdoc-glob=pat\n",
      "                        Text files matching this pattern will be checked for\n",
      "                        doctests. This option may be specified multiple times.\n",
      "                        XDoctest does not check any text files by default. For\n",
      "                        compatibility with doctest set this to test*.txt\n",
      "  --xdoctest-ignore-syntax-errors\n",
      "                        Ignore xdoctest SyntaxErrors\n",
      "  --xdoctest-style={freeform,google,auto}, --xdoc-style={freeform,google,auto}\n",
      "                        Basic style used to write doctests\n",
      "  --xdoctest-analysis={static,dynamic,auto}, --xdoc-analysis={static,dynamic,auto}\n",
      "                        How doctests are collected. Can either be static,\n",
      "                        dynamic, or auto\n",
      "  --xdoctest-colored=XDOCTEST_COLORED, --xdoc-colored=XDOCTEST_COLORED\n",
      "                        Enable or disable ANSI coloration in stdout\n",
      "  --xdoctest-nocolor, --xdoc-nocolor\n",
      "                        Disable ANSI coloration in stdout\n",
      "  --xdoctest-offset, --xdoc-offset\n",
      "                        If True formatted source linenumbers will agree with\n",
      "                        their location in the source file. Otherwise they will\n",
      "                        be relative to the doctest itself.\n",
      "  --xdoctest-report={none,cdiff,ndiff,udiff,only_first_failure}, --xdoc-report={none,cdiff,ndiff,udiff,only_first_failure}\n",
      "                        Choose another output format for diffs on xdoctest\n",
      "                        failure\n",
      "  --xdoctest-options=XDOCTEST_OPTIONS, --xdoc-options=XDOCTEST_OPTIONS\n",
      "                        Default directive flags for doctests\n",
      "  --xdoctest-global-exec=XDOCTEST_GLOBAL_EXEC, --xdoc-global-exec=XDOCTEST_GLOBAL_EXEC\n",
      "                        Custom Python code to execute before every test\n",
      "  --xdoctest-supress-import-errors, --xdoc-supress-import-errors\n",
      "                        Removes tracebacks from errors in implicit imports\n",
      "  --xdoctest-verbose=XDOCTEST_VERBOSE, --xdoc-verbose=XDOCTEST_VERBOSE\n",
      "                        Verbosity level. 0 is silent, 1 prints out test names, 2\n",
      "                        additionally prints test stdout, 3 additionally prints\n",
      "                        test source\n",
      "  --xdoctest-quiet, --xdoc-quiet\n",
      "                        sets verbosity to 1\n",
      "  --xdoctest-silent, --xdoc-silent\n",
      "                        sets verbosity to 0\n",
      "\n",
      "test session debugging and configuration:\n",
      "  --basetemp=dir        Base temporary directory for this test run. (Warning:\n",
      "                        this directory is removed if it exists.)\n",
      "  -V, --version         Display pytest version and information about plugins.\n",
      "                        When given twice, also display information about\n",
      "                        plugins.\n",
      "  -h, --help            Show help message and configuration info\n",
      "  -p name               Early-load given plugin module name or entry point\n",
      "                        (multi-allowed). To avoid loading of plugins, use the\n",
      "                        `no:` prefix, e.g. `no:doctest`.\n",
      "  --trace-config        Trace considerations of conftest.py files\n",
      "  --debug=[DEBUG_FILE_NAME]\n",
      "                        Store internal tracing debug information in this log\n",
      "                        file. This file is opened with 'w' and truncated as a\n",
      "                        result, care advised. Default: pytestdebug.log.\n",
      "  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI\n",
      "                        Override ini option with \"option=value\" style, e.g. `-o\n",
      "                        xfail_strict=True -o cache_dir=cache`.\n",
      "  --assert=MODE         Control assertion debugging tools.\n",
      "                        'plain' performs no assertion debugging.\n",
      "                        'rewrite' (the default) rewrites assert statements in\n",
      "                        test modules on import to provide assert expression\n",
      "                        information.\n",
      "  --setup-only          Only setup fixtures, do not execute tests\n",
      "  --setup-show          Show setup of fixtures while executing tests\n",
      "  --setup-plan          Show what fixtures and tests would be executed but don't\n",
      "                        execute anything\n",
      "\n",
      "logging:\n",
      "  --log-level=LEVEL     Level of messages to catch/display. Not set by default,\n",
      "                        so it depends on the root/parent log handler's effective\n",
      "                        level, where it is \"WARNING\" by default.\n",
      "  --log-format=LOG_FORMAT\n",
      "                        Log format used by the logging module\n",
      "  --log-date-format=LOG_DATE_FORMAT\n",
      "                        Log date format used by the logging module\n",
      "  --log-cli-level=LOG_CLI_LEVEL\n",
      "                        CLI logging level\n",
      "  --log-cli-format=LOG_CLI_FORMAT\n",
      "                        Log format used by the logging module\n",
      "  --log-cli-date-format=LOG_CLI_DATE_FORMAT\n",
      "                        Log date format used by the logging module\n",
      "  --log-file=LOG_FILE   Path to a file when logging will be written to\n",
      "  --log-file-level=LOG_FILE_LEVEL\n",
      "                        Log file logging level\n",
      "  --log-file-format=LOG_FILE_FORMAT\n",
      "                        Log format used by the logging module\n",
      "  --log-file-date-format=LOG_FILE_DATE_FORMAT\n",
      "                        Log date format used by the logging module\n",
      "  --log-auto-indent=LOG_AUTO_INDENT\n",
      "                        Auto-indent multiline messages passed to the logging\n",
      "                        module. Accepts true|on, false|off or an integer.\n",
      "\n",
      "re-run failing tests to eliminate flaky failures:\n",
      "  --only-rerun=ONLY_RERUN\n",
      "                        If passed, only rerun errors matching the regex\n",
      "                        provided. Pass this flag multiple times to accumulate a\n",
      "                        list of regexes to match\n",
      "  --reruns=RERUNS       number of times to re-run failed tests. defaults to 0.\n",
      "  --reruns-delay=RERUNS_DELAY\n",
      "                        add time (seconds) delay between reruns.\n",
      "  --rerun-except=RERUN_EXCEPT\n",
      "                        If passed, only rerun errors other than matching the\n",
      "                        regex provided. Pass this flag multiple times to\n",
      "                        accumulate a list of regexes to match\n",
      "\n",
      "Hypothesis:\n",
      "  --hypothesis-profile=HYPOTHESIS_PROFILE\n",
      "                        Load in a registered hypothesis.settings profile\n",
      "  --hypothesis-verbosity={quiet,normal,verbose,debug}\n",
      "                        Override profile with verbosity setting specified\n",
      "  --hypothesis-show-statistics\n",
      "                        Configure when statistics are printed\n",
      "  --hypothesis-seed=HYPOTHESIS_SEED\n",
      "                        Set a seed to use for all Hypothesis tests\n",
      "\n",
      "distributed and subprocess testing:\n",
      "  -n numprocesses, --numprocesses=numprocesses\n",
      "                        Shortcut for '--dist=load --tx=NUM*popen'. With 'auto',\n",
      "                        attempt to detect physical CPU count. With 'logical',\n",
      "                        detect logical CPU count. If physical CPU count cannot\n",
      "                        be found, falls back to logical count. This will be 0\n",
      "                        when used with --pdb.\n",
      "  --maxprocesses=maxprocesses\n",
      "                        limit the maximum number of workers to process the tests\n",
      "                        when using --numprocesses=auto\n",
      "  --max-worker-restart=MAXWORKERRESTART\n",
      "                        maximum number of workers that can be restarted when\n",
      "                        crashed (set to zero to disable this feature)\n",
      "  --dist=distmode       set mode for distributing tests to exec environments.\n",
      "                        each: send each test to all available environments.\n",
      "                        load: load balance by sending any pending test to any\n",
      "                        available environment.\n",
      "                        loadscope: load balance by sending pending groups of\n",
      "                        tests in the same scope to any available environment.\n",
      "                        loadfile: load balance by sending test grouped by file\n",
      "                        to any available environment.\n",
      "                        loadgroup: like load, but sends tests marked with\n",
      "                        'xdist_group' to the same worker.\n",
      "                        (default) no: run tests inprocess, don't distribute.\n",
      "  --tx=xspec            add a test execution environment. some examples: --tx\n",
      "                        popen//python=python2.5 --tx socket=192.168.1.102:8888\n",
      "                        --tx ssh=user@codespeak.net//chdir=testcache\n",
      "  -d                    load-balance tests.  shortcut for '--dist=load'\n",
      "  --rsyncdir=DIR        add directory for rsyncing to remote tx nodes.\n",
      "  --rsyncignore=GLOB    add expression for ignores when rsyncing to remote tx\n",
      "                        nodes.\n",
      "  --testrunuid=TESTRUNUID\n",
      "                        provide an identifier shared amongst all workers as the\n",
      "                        value of the 'testrun_uid' fixture,\n",
      "                        ,if not provided, 'testrun_uid' is filled with a new\n",
      "                        unique string on every test run.\n",
      "  -f, --looponfail      run tests in subprocess, wait for modified files and re-\n",
      "                        run failing test set until all pass.\n",
      "\n",
      "shard:\n",
      "  --shard-id=SHARD_ID   Number of this shard.\n",
      "  --num-shards=NUM_SHARDS\n",
      "                        Total number of shards.\n",
      "\n",
      "[pytest] ini-options in the first pytest.ini|tox.ini|setup.cfg file found:\n",
      "\n",
      "  markers (linelist):   Markers for test functions\n",
      "  empty_parameter_set_mark (string):\n",
      "                        Default marker for empty parametersets\n",
      "  norecursedirs (args): Directory patterns to avoid for recursion\n",
      "  testpaths (args):     Directories to search for tests when no files or\n",
      "                        directories are given on the command line\n",
      "  filterwarnings (linelist):\n",
      "                        Each line specifies a pattern for\n",
      "                        warnings.filterwarnings. Processed after\n",
      "                        -W/--pythonwarnings.\n",
      "  usefixtures (args):   List of default fixtures to be used with this project\n",
      "  python_files (args):  Glob-style file patterns for Python test module\n",
      "                        discovery\n",
      "  python_classes (args):\n",
      "                        Prefixes or glob names for Python test class discovery\n",
      "  python_functions (args):\n",
      "                        Prefixes or glob names for Python test function and\n",
      "                        method discovery\n",
      "  disable_test_id_escaping_and_forfeit_all_rights_to_community_support (bool):\n",
      "                        Disable string escape non-ASCII characters, might cause\n",
      "                        unwanted side effects(use at your own risk)\n",
      "  console_output_style (string):\n",
      "                        Console output: \"classic\", or with additional progress\n",
      "                        information (\"progress\" (percentage) | \"count\")\n",
      "  xfail_strict (bool):  Default for the strict parameter of xfail markers when\n",
      "                        not given explicitly (default: False)\n",
      "  enable_assertion_pass_hook (bool):\n",
      "                        Enables the pytest_assertion_pass hook. Make sure to\n",
      "                        delete any previously generated pyc cache files.\n",
      "  junit_suite_name (string):\n",
      "                        Test suite name for JUnit report\n",
      "  junit_logging (string):\n",
      "                        Write captured log messages to JUnit report: one of\n",
      "                        no|log|system-out|system-err|out-err|all\n",
      "  junit_log_passing_tests (bool):\n",
      "                        Capture log information for passing tests to JUnit\n",
      "                        report:\n",
      "  junit_duration_report (string):\n",
      "                        Duration time to report: one of total|call\n",
      "  junit_family (string):\n",
      "                        Emit XML for schema: one of legacy|xunit1|xunit2\n",
      "  doctest_optionflags (args):\n",
      "                        Option flags for doctests\n",
      "  doctest_encoding (string):\n",
      "                        Encoding used for doctest files\n",
      "  cache_dir (string):   Cache directory path\n",
      "  log_level (string):   Default value for --log-level\n",
      "  log_format (string):  Default value for --log-format\n",
      "  log_date_format (string):\n",
      "                        Default value for --log-date-format\n",
      "  log_cli (bool):       Enable log display during test run (also known as \"live\n",
      "                        logging\")\n",
      "  log_cli_level (string):\n",
      "                        Default value for --log-cli-level\n",
      "  log_cli_format (string):\n",
      "                        Default value for --log-cli-format\n",
      "  log_cli_date_format (string):\n",
      "                        Default value for --log-cli-date-format\n",
      "  log_file (string):    Default value for --log-file\n",
      "  log_file_level (string):\n",
      "                        Default value for --log-file-level\n",
      "  log_file_format (string):\n",
      "                        Default value for --log-file-format\n",
      "  log_file_date_format (string):\n",
      "                        Default value for --log-file-date-format\n",
      "  log_auto_indent (string):\n",
      "                        Default value for --log-auto-indent\n",
      "  pythonpath (paths):   Add paths to sys.path\n",
      "  faulthandler_timeout (string):\n",
      "                        Dump the traceback of all threads if a test takes more\n",
      "                        than TIMEOUT seconds to finish\n",
      "  addopts (args):       Extra command line options\n",
      "  minversion (string):  Minimally required pytest version\n",
      "  required_plugins (args):\n",
      "                        Plugins that must be present for pytest to run\n",
      "  xdoctest_encoding (string):\n",
      "                        encoding used for xdoctest files\n",
      "  rsyncdirs (paths):    list of (relative) paths to be rsynced for remote\n",
      "                        distributed testing.\n",
      "  rsyncignore (paths):  list of (relative) glob-style paths to be ignored for\n",
      "                        rsyncing.\n",
      "  looponfailroots (paths):\n",
      "                        directories to check for changes. Default: current\n",
      "                        directory.\n",
      "\n",
      "Environment variables:\n",
      "  PYTEST_ADDOPTS           Extra command line options\n",
      "  PYTEST_PLUGINS           Comma-separated plugins to load during startup\n",
      "  PYTEST_DISABLE_PLUGIN_AUTOLOAD Set to disable plugin auto-loading\n",
      "  PYTEST_DEBUG             Set to enable debug tracing of pytest's internals\n",
      "\n",
      "\n",
      "to see available markers type: pytest --markers\n",
      "to see available fixtures type: pytest --fixtures\n",
      "(shown according to specified file_or_dir or current dir if not specified; fixtures with leading '_' are only shown with the '-v' option\n"
     ]
    }
   ],
   "source": [
    "!echo \"pytest --help\" | docker-compose run flashattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "--capture=tee-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "c18e863d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flash-attention_flashattention_run ... \n",
      "\u001b[1Bting flash-attention_flashattention_run ... \u001b[32mdone\u001b[0m\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 22.12 (build 49968248)\n",
      "PyTorch Version 1.14.0a0+410ce96\n",
      "\n",
      "Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Copyright (c) 2014-2022 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "WARNING: CUDA Minor Version Compatibility mode ENABLED.\n",
      "  Using driver version 515.86.01 which has support for CUDA 11.7.  This container\n",
      "  was built with CUDA 11.8 and will be run in Minor Version Compatibility mode.\n",
      "  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use\n",
      "  with this container but was unavailable:\n",
      "  [[]]\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "/bin/bash: line 1: --capture=tee-sys: command not found\n",
      "\u001b[31mERROR\u001b[0m: 127\n"
     ]
    }
   ],
   "source": [
    "!echo \"pytest --capture=tee-sys tests/test_flash_attn_lse.py\"  | docker-compose run flashattention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3202a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
