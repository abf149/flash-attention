{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28cd50e",
   "metadata": {},
   "source": [
    "## Commit\n",
    "\n",
    "Running the cell below copies any local source code modifications into the FlashAttention install directory on the FlashAttention docker image, and then commits the Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "59630d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "Untagged: flash:flattened_live\n",
      "Deleted: sha256:d5c093f2bff4b3ccc4e829bb7bc17512935bf1f857826d7efd747ac23809687a\n",
      "Creating flash-attention_flashattention_run ... \n",
      "\u001b[1Bting flash-attention_flashattention_run ... \u001b[32mdone\u001b[0m\n",
      "\n",
      "torch.__version__  = 1.14.0a0+410ce96\n",
      "\n",
      "\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing flash_attn.egg-info/PKG-INFO\n",
      "writing dependency_links to flash_attn.egg-info/dependency_links.txt\n",
      "writing requirements to flash_attn.egg-info/requires.txt\n",
      "writing top-level names to flash_attn.egg-info/top_level.txt\n",
      "reading manifest file 'flash_attn.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "warning: no files found matching '*.cu' under directory 'flash_attn'\n",
      "warning: no files found matching '*.h' under directory 'flash_attn'\n",
      "warning: no files found matching '*.cuh' under directory 'flash_attn'\n",
      "warning: no files found matching '*.cpp' under directory 'flash_attn'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'AUTHORS'\n",
      "writing manifest file 'flash_attn.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying flash_attn/flash_attn_interface.py -> build/lib.linux-x86_64-3.8/flash_attn\n",
      "running build_ext\n",
      "building 'flash_attn_cuda' extension\n",
      "Emitting ninja build file /home/workspace/build/temp.linux-x86_64-3.8/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/1] c++ -MMD -MF /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/fmha_api.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/workspace/csrc/flash_attn -I/home/workspace/csrc/flash_attn/src -I/home/workspace/csrc/flash_attn/cutlass/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/workspace/csrc/flash_attn/fmha_api.cpp -o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/fmha_api.o -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=flash_attn_cuda -D_GLIBCXX_USE_CXX11_ABI=1\n",
      "In file included from /home/workspace/csrc/flash_attn/src/fmha.h:42,\n",
      "                 from /home/workspace/csrc/flash_attn/fmha_api.cpp:33:\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h: In function ‘void set_alpha(uint32_t&, float, Data_type)’:\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h:63:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "   63 |         alpha = reinterpret_cast<const uint32_t &>( h2 );\n",
      "      |                                                     ^~\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h:68:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "   68 |         alpha = reinterpret_cast<const uint32_t &>( h2 );\n",
      "      |                                                     ^~\n",
      "/home/workspace/csrc/flash_attn/src/fmha_utils.h:70:53: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "   70 |         alpha = reinterpret_cast<const uint32_t &>( norm );\n",
      "      |                                                     ^~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp: In function ‘void set_params_fprop(FMHA_fprop_params&, size_t, size_t, size_t, size_t, size_t, at::Tensor, at::Tensor, at::Tensor, at::Tensor, void*, void*, void*, void*, void*, float, float, bool, int)’:\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:64:38: warning: ‘void* memset(void*, int, size_t)’ clearing an object of non-trivial type ‘struct FMHA_fprop_params’; use assignment or value-initialization instead [-Wclass-memaccess]\n",
      "   64 |     memset(&params, 0, sizeof(params));\n",
      "      |                                      ^\n",
      "In file included from /home/workspace/csrc/flash_attn/fmha_api.cpp:33:\n",
      "/home/workspace/csrc/flash_attn/src/fmha.h:75:8: note: ‘struct FMHA_fprop_params’ declared here\n",
      "   75 | struct FMHA_fprop_params : public Qkv_params {\n",
      "      |        ^~~~~~~~~~~~~~~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:60:15: warning: unused variable ‘acc_type’ [-Wunused-variable]\n",
      "   60 |     Data_type acc_type = DATA_TYPE_FP32;\n",
      "      |               ^~~~~~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp: In function ‘std::vector<at::Tensor> mha_fwd(const at::Tensor&, const at::Tensor&, const at::Tensor&, at::Tensor&, const at::Tensor&, const at::Tensor&, int, int, float, float, bool, bool, bool, int, c10::optional<at::Generator>)’:\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:265:10: warning: unused variable ‘is_sm80’ [-Wunused-variable]\n",
      "  265 |     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;\n",
      "      |          ^~~~~~~\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp: In function ‘std::vector<at::Tensor> mha_fwd_block(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int, int, float, float, bool, bool, c10::optional<at::Generator>)’:\n",
      "/home/workspace/csrc/flash_attn/fmha_api.cpp:596:10: warning: unused variable ‘is_sm80’ [-Wunused-variable]\n",
      "  596 |     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;\n",
      "      |          ^~~~~~~\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/fmha_api.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_fwd_hdim32.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_fwd_hdim64.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_fwd_hdim128.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_bwd_hdim32.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_bwd_hdim64.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_bwd_hdim128.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.o /home/workspace/build/temp.linux-x86_64-3.8/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.8/flash_attn_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn_cuda.cpython-38-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/losses\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/losses/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/losses\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/losses/cross_entropy.py -> build/bdist.linux-x86_64/egg/flash_attn/losses\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_triton_onewritehead.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_triton_og.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_interface.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/layers/patch_embed.py -> build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/layers/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/layers/rotary.py -> build/bdist.linux-x86_64/egg/flash_attn/layers\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_blocksparse_attn_interface.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/fused_softmax.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attn_triton.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/bert_padding.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_blocksparse_attention.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/activations.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/rms_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/layer_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/ops/fused_dense.py -> build/bdist.linux-x86_64/egg/flash_attn/ops\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/pretrained.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/generation.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/benchmark.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/utils/distributed.py -> build/bdist.linux-x86_64/egg/flash_attn/utils\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/embedding.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/block.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/mlp.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/modules/mha.py -> build/bdist.linux-x86_64/egg/flash_attn/modules\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/flash_attention.py -> build/bdist.linux-x86_64/egg/flash_attn\n",
      "creating build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/gpt.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/llama.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/gptj.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/bert.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/vit.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "copying build/lib.linux-x86_64-3.8/flash_attn/models/opt.py -> build/bdist.linux-x86_64/egg/flash_attn/models\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/losses/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/losses/cross_entropy.py to cross_entropy.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_onewritehead.py to flash_attn_triton_onewritehead.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_og.py to flash_attn_triton_og.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_interface.py to flash_attn_interface.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/patch_embed.py to patch_embed.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/rotary.py to rotary.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_blocksparse_attn_interface.py to flash_blocksparse_attn_interface.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/fused_softmax.py to fused_softmax.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton.py to flash_attn_triton.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/bert_padding.py to bert_padding.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_blocksparse_attention.py to flash_blocksparse_attention.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/activations.py to activations.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/rms_norm.py to rms_norm.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/layer_norm.py to layer_norm.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/fused_dense.py to fused_dense.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/pretrained.py to pretrained.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/generation.py to generation.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/benchmark.py to benchmark.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/distributed.py to distributed.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/embedding.py to embedding.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/block.py to block.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/mlp.py to mlp.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/mha.py to mha.cpython-38.pyc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attention.py to flash_attention.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gpt.py to gpt.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/llama.py to llama.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gpt_neox.py to gpt_neox.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gptj.py to gptj.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/bert.py to bert.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/vit.py to vit.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/opt.py to opt.cpython-38.pyc\n",
      "creating stub loader for flash_attn_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flash_attn_cuda.py to flash_attn_cuda.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flash_attn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.flash_attn_cuda.cpython-38: module references __file__\n",
      "creating 'dist/flash_attn-1.0.4-py3.8-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing flash_attn-1.0.4-py3.8-linux-x86_64.egg\n",
      "removing '/usr/local/lib/python3.8/dist-packages/flash_attn-1.0.4-py3.8-linux-x86_64.egg' (and everything under it)\n",
      "creating /usr/local/lib/python3.8/dist-packages/flash_attn-1.0.4-py3.8-linux-x86_64.egg\n",
      "Extracting flash_attn-1.0.4-py3.8-linux-x86_64.egg to /usr/local/lib/python3.8/dist-packages\n",
      "flash-attn 1.0.4 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /usr/local/lib/python3.8/dist-packages/flash_attn-1.0.4-py3.8-linux-x86_64.egg\n",
      "Processing dependencies for flash-attn==1.0.4\n",
      "Searching for packaging==22.0\n",
      "Best match: packaging 22.0\n",
      "Adding packaging 22.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for einops==0.6.1\n",
      "Best match: einops 0.6.1\n",
      "Adding einops 0.6.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for torch==1.14.0a0+410ce96\n",
      "Best match: torch 1.14.0a0+410ce96\n",
      "Adding torch 1.14.0a0+410ce96 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
      "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
      "Installing torchrun script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for networkx==2.6.3\n",
      "Best match: networkx 2.6.3\n",
      "Adding networkx 2.6.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for sympy==1.11.1\n",
      "Best match: sympy 1.11.1\n",
      "Adding sympy 1.11.1 to easy-install.pth file\n",
      "Installing isympy script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for typing-extensions==4.4.0\n",
      "Best match: typing-extensions 4.4.0\n",
      "Adding typing-extensions 4.4.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Searching for mpmath==1.2.1\n",
      "Best match: mpmath 1.2.1\n",
      "Adding mpmath 1.2.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages\n",
      "Finished processing dependencies for flash-attn==1.0.4\n",
      "done\n",
      "commiting container\n",
      "sha256:d1b8c0e0dbefa51e84fc8e15f0f2c6044dcea313aa0309a31da15c5a7bce912e\n",
      "force-quitting docker\n",
      "CONTAINER ID   IMAGE             COMMAND       CREATED          STATUS          PORTS     NAMES\n",
      "034460f74b1f   flash:flattened   \"/bin/bash\"   39 seconds ago   Up 38 seconds             flash-attention_flashattention_run_38b5d719a13c\n",
      "034460f74b1f\n",
      "\u001b[31mERROR\u001b[0m: 137\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!./build_commit.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb5fea",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "--capture=tee-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "c18e863d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flash-attention_flashattention_run ... \n",
      "\u001b[1Bting flash-attention_flashattention_run ... \u001b[32mdone\u001b[0m============================= test session starts ==============================\n",
      "platform linux -- Python 3.8.10, pytest-7.2.0, pluggy-1.0.0\n",
      "rootdir: /home/workspace\n",
      "plugins: rerunfailures-10.3, xdoctest-1.0.2, hypothesis-5.35.1, xdist-3.1.0, shard-0.1.2, hydra-core-1.3.1\n",
      "collected 3 items\n",
      "Running 3 items in this shard\n",
      "\n",
      "tests/test_flash_attn_lse.py ...                                         [100%]\n",
      "\n",
      "============================== 3 passed in 1.74s ===============================\n"
     ]
    }
   ],
   "source": [
    "!echo \"pytest --capture=tee-sys tests/test_flash_attn_lse.py\"  | docker-compose run flashattention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3202a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
